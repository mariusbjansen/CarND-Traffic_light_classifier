{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The traffic light is RED\n",
      "6.060825347900391\n",
      "The traffic light is RED\n",
      "0.09302783012390137\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# only for testing/plotting -> dont introduce in ROS node\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# parameters\n",
    "PATH_TO_CKPT = 'ssd_mobilenet_v1_coco_2017_11_17.pb'\n",
    "#RED\n",
    "TEST_IMAGE_PATH = '/home/bruno/udacity/carnd3/final_project/models/research/object_detection/test_images/train/0/1092.png'\n",
    "# YELLOW\n",
    "#TEST_IMAGE_PATH = '/home/bruno/udacity/carnd3/final_project/models/research/object_detection/test_images/train/1/306.png'\n",
    "# GREEN\n",
    "#TEST_IMAGE_PATH = '/home/bruno/udacity/carnd3/final_project/models/research/object_detection/test_images/train/2/293.png'\n",
    "\n",
    "\n",
    "class TLClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "          od_graph_def = tf.GraphDef()\n",
    "          with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "            \n",
    "        self.sess = None\n",
    "        self.setup = False\n",
    "        self.tensor_dict = None\n",
    "        self.image_tensor = None\n",
    "\n",
    "    def get_classification(self, image):\n",
    "        # detection call\n",
    "        output = self.run_inference_for_single_image(image)\n",
    "        \n",
    "        # only for testing/plotting -> dont introduce in ROS node\n",
    "        CLASS_TRAFFIC_LIGHT = 10\n",
    "        THRESHOLD_SCORE = 0.6\n",
    "        %matplotlib inline\n",
    "        \n",
    "        boxes = output['detection_boxes']\n",
    "        classes =  output['detection_classes']\n",
    "        scores = output['detection_scores']\n",
    "        \n",
    "        img = cv2.imread(TEST_IMAGE_PATH)\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        idxTL = np.where(classes == CLASS_TRAFFIC_LIGHT)  \n",
    "        \n",
    "        bestThresh = THRESHOLD_SCORE\n",
    "        match = None\n",
    "            \n",
    "        for i in idxTL[0].tolist():\n",
    "            if scores[i] > THRESHOLD_SCORE and scores[i] > bestThresh:\n",
    "                match = i\n",
    "                bestThresh = scores[i]\n",
    "                  \n",
    "        \n",
    "        if match is not None:\n",
    "            # extract/crop region of interest and plot\n",
    "            right_y = int(boxes[match][0]*height)\n",
    "            left_y = int(boxes[match][2]*height)\n",
    "            left_x = int(boxes[match][1]*width)\n",
    "            right_x = int(boxes[match][3]*width)\n",
    "                  \n",
    "            roi = img[right_y:left_y, left_x:right_x]\n",
    "            cv2.imwrite('/home/bruno/analyze.png',roi)\n",
    "            \n",
    "            result = self.red_green_yellow(roi)\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.imshow(roi)\n",
    "            \n",
    "            print('The traffic light is', result)\n",
    "        else:\n",
    "            print('No traffic light')\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return None\n",
    "\n",
    "    \n",
    "    def run_inference_for_single_image(self, image):\n",
    "      with self.detection_graph.as_default():\n",
    "        if (self.setup == False):\n",
    "            with tf.Session() as self.sess:\n",
    "              # Get handles to input and output tensors\n",
    "              ops = tf.get_default_graph().get_operations()\n",
    "              all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "              self.tensor_dict = {}\n",
    "              for key in [\n",
    "                  'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                  'detection_classes', 'detection_masks'\n",
    "              ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                  self.tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                      tensor_name)\n",
    "              if 'detection_masks' in self.tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(self.tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(self.tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(self.tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                self.tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
    "              self.image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "              self.setup = True\n",
    "        \n",
    "    \n",
    "        if (self.setup == True):\n",
    "            # Run inference\n",
    "            output_dict = self.sess.run(self.tensor_dict,feed_dict={self.image_tensor: np.expand_dims(image, 0)})\n",
    "        \n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "                return output_dict\n",
    "        \n",
    "        return output_dict\n",
    "    \n",
    "    \n",
    "\n",
    "      \n",
    "    def findNonZero(self, image_in):\n",
    "      rows, cols, _ = image_in.shape\n",
    "      counter = 0\n",
    "    \n",
    "      for row in range(rows):\n",
    "        for col in range(cols):\n",
    "          pixel = image_in[row, col]\n",
    "          if sum(pixel) != 0:\n",
    "            counter = counter + 1\n",
    "    \n",
    "      return counter\n",
    "    \n",
    "    def red_green_yellow(self, image_in):\n",
    "      hsv = cv2.cvtColor(image_in, cv2.COLOR_BGR2HSV)\n",
    "      \n",
    "      S_low = 50\n",
    "      V_low = 80\n",
    "    \n",
    "      '''\n",
    "      # GREEN\n",
    "      lower_green = np.array([125,S_low,V_low])\n",
    "      upper_green = np.array([140,255,255])\n",
    "      green_mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "      green_result = cv2.bitwise_and(image_in, image_in, mask = green_mask)\n",
    "      '''\n",
    "        \n",
    "      # YELLOW OR GREEN\n",
    "      lower_yellow = np.array([50,S_low,V_low])\n",
    "      upper_yellow = np.array([140,255,255])\n",
    "      yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "      yellow_result = cv2.bitwise_and(image_in, image_in, mask = yellow_mask)\n",
    "    \n",
    "      # RED\n",
    "      lower_red = np.array([0,S_low,V_low])\n",
    "      upper_red = np.array([10,255,255])\n",
    "      red_mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "      red_result = cv2.bitwise_and(image_in, image_in, mask = red_mask)\n",
    "    \n",
    "      #sum_green = self.findNonZero(green_result)\n",
    "      sum_yellow_or_green = self.findNonZero(yellow_result)\n",
    "      sum_red = self.findNonZero(red_result)\n",
    "    \n",
    "      if sum_red >= sum_yellow_or_green:\n",
    "        return 'RED'\n",
    "      return 'YELLOW OR GREEN'\n",
    "\n",
    "        \n",
    "# read image in\n",
    "t = time.time()\n",
    "cvimage = cv2.imread(TEST_IMAGE_PATH)\n",
    "cvimage = cvimage[...,::-1]\n",
    "(im_height, im_width) = cvimage.shape[:2]\n",
    "npimage = np.array(cvimage.reshape(im_height, im_width, 3)).astype(np.uint8)        \n",
    "classifier = TLClassifier() \n",
    "classifier.get_classification(npimage)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)\n",
    "\n",
    "t = time.time()\n",
    "cvimage = cv2.imread(TEST_IMAGE_PATH)\n",
    "cvimage = cvimage[...,::-1]\n",
    "(im_height, im_width) = cvimage.shape[:2]\n",
    "npimage = np.array(cvimage.reshape(im_height, im_width, 3)).astype(np.uint8)        \n",
    "classifier.get_classification(npimage)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
